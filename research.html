<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <title>_D N W_</title>
  <link rel="stylesheet" type="text/css" href="personalsite1.css">
</head>

<body >
<br><br><br><br>

<table border="0" align="center" cellpadding=15>
  <tr>
    <td width=100></td>
    <td width=420></td>
    <td width=420></td>
    <td width=100></td>
    <tr>
      <td colspan=1></td>
      <td class="middle" height=50 colspan=2>
      <p align="center">
        <a href="index.html">Contact</a> |
        <a href="research.html">Research</a> |
        <a href="img/dnw_cv.pdf">CV</a> |
        <a href="https://gitlab.com/opensourcedave">Code</a> |
        <a href="resources.php">Resources</a>
      </p>
      </td>
      <td colspan=2></td>
    </tr>
  </tr>

  <tr>
    <td colspan="4"></td>
  </tr>
  <tr>
    <td colspan=1></td>

    <td colspan=2 width=840">
    <p align="left">
          The human visual system is absolutley remarkable.  The physiology of our brains is able to reconstruct a super accurate depiction of our external environment with virtually no latency.  On top of this, our visual system is able to identify and classify objects within our environment with what feels like no effort.  These facts are all more remarkable when you consider how uncertain the natural environment is and how many variables are at play. Moreover, the information our visual systems recieve as input, is always incomplete; our visual system, which includes not only our eyes, but the majority of our brain mass, is a system of inference.  This inference occurs at both stages of feature extraction and combination. Such features include: color and luminance at low levels, temporal and spatial disparity at mid levels, shape and texture at even higher levels.
      </p>
      <p>
          I study the three dimensional aspects of perception in mid-level visual processing.  When we observe a scene, two slightly different 2D images are projected on our retinas.  We call the difference in these images spatial or binocular disparity.
          How does the human brain use binocular disparity to reconstruct a 3D scene? What mathematical/computational operations are our brains utilizing to accomplish this?  These are the questions I am interested in answering.
      </p>
      <p align="left">
          My research primarily revolves around psychophysics (the measurement of human thresholds of detection under very specific circumstances) in natural scenes. I both gather human perceptual data and attempt to model those perceptions under a probabalistic framework.  Our modelling framework is both normative and principled in that we create models that are idealized given known human constraints, then attempt to determine how the visual systems differ.
      </p>
      <p align="left">
          Topics assosiated with my labs modelling include:<br>
          <ul>
              <li>Dimensionality Reduction</li>
              <li>Signal detection theory</li>
              <li>(Optimal) decision theory</li>
              <li>Ideal observer models</li>
              <li>Bayesian Inference</li>
              <li>Dimensionality reduction</li>
              <li>Machine learning</li>
          </ul>
      </p>
    </td>

    <td colspan="1">
    </td>
  </tr>

  <tr><td colspan=4></tr>

  <tr>
    <td colspan=1></td>
    <td colspan=2 class="middle" width=840>
      <p align="justify">
      </p>
    </td>
    <td colspan=2></td>

  </tr>

</table>
</div>

<br><br><br><br>
</body>
</html>
